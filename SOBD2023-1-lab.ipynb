{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2936762d-13ef-4f57-ab36-704236d50b38",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;font-size:200%;;\">Лабораторная работа №1 </h2>\n",
    "<h3  style=\"text-align:center;\"><span class=\"label label-success\">Проведение разведочного анализа датасета</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4db554-4f97-4112-beba-b75aa6dfac36",
   "metadata": {},
   "source": [
    "1. Initialize pyspark framework and load data into pyspark's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceba910b-143e-49f5-a6a0-78b7fc806ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|           timestamp|actual_consumption|           load_00|           load_01|           load_02|           load_03|           load_04|           load_05|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|2015-06-12T02:00:...| 28.85647308677435|26.481838220094716|23.421641718692797| 20.57187549747037|  20.2664084859748|18.748720578799485| 19.16973657657757|\n",
      "|2015-06-12T02:15:...|26.465026293136184| 24.16895244093518|21.870495741922895|  20.2664084859748|18.748720578799485| 19.16973657657757|18.706966825755106|\n",
      "|2015-06-12T02:45:...| 20.25967533160001| 18.89810303243156|16.316711645913593| 19.16973657657757|18.706966825755106|18.683137459003262|18.713580181675162|\n",
      "|2015-06-12T03:30:...| 34.02441665679216|30.685165498424723|27.764159763763445|18.713580181675162| 18.66372483500576| 18.65349471343304|18.737393569055712|\n",
      "|2015-06-12T03:45:...| 27.76655887942761| 23.83923138369042|19.938092104194208| 18.66372483500576| 18.65349471343304|18.737393569055712|19.681227076959907|\n",
      "|2015-06-12T04:00:...|21.965351288206875| 19.87241013410619|17.683894140561296| 18.65349471343304|18.737393569055712|19.681227076959907|21.184395715401756|\n",
      "|2015-06-12T04:45:...|19.669371432438492|19.451492568597562|20.091377205183377|21.184395715401756|21.073017700373818|  24.0590058470385| 53.76794531338368|\n",
      "|2015-06-12T06:00:...|34.808836662955585| 64.26065422484497|  63.9542601070644|54.877995038750235| 47.17394273337662| 44.40903171018536|42.686701922238704|\n",
      "|2015-06-12T06:30:...| 64.99389130175112| 67.08502827436679| 60.32135816619418| 44.40903171018536|42.686701922238704|44.722764414324004| 43.84000128844465|\n",
      "|2015-06-12T07:00:...|58.821953768469385| 53.48626547155905| 49.17466285012857|44.722764414324004| 43.84000128844465| 42.76041295505193|42.162540039263924|\n",
      "|2015-06-12T07:30:...|  44.2393790088594|44.063734828118704| 40.95335281742692| 42.76041295505193|42.162540039263924| 40.90298418549262|40.608921712024554|\n",
      "|2015-06-12T08:30:...| 32.39829648174345| 30.59761884122552|29.758541458705324| 43.45752237220725| 53.64354880174302| 81.01813129882223| 88.09211449083814|\n",
      "|2015-06-12T08:45:...| 29.91774721276015| 32.40381609718773|38.052549881350416| 53.64354880174302| 81.01813129882223| 88.09211449083814| 89.91803119467284|\n",
      "|2015-06-12T09:30:...| 71.53019431456923| 99.40373678269958|106.98026973320523| 89.91803119467284| 90.51311691093382| 90.26172832164724| 87.79945574972264|\n",
      "|2015-06-12T10:15:...|108.87526929359883|105.34214505154098|100.93284593252233| 87.79945574972264| 82.30059378178808| 69.60430345878765| 66.95604846277429|\n",
      "|2015-06-12T12:15:...| 37.85264086537063| 42.37077981020884| 46.80054535457785|49.842609905176246| 53.23056155081611|52.609602169126106|51.771169725358654|\n",
      "|2015-06-12T12:45:...|28.881930936872962| 33.63939179818836| 41.83660898501259|52.609602169126106|51.771169725358654| 43.81161672471785|41.320168019835414|\n",
      "|2015-06-12T15:15:...| 36.92661156803369|37.657918706549445|38.032745451474675| 41.84999845682463|40.541467263108814| 40.49269474118234| 41.29678702929928|\n",
      "|2015-06-12T16:00:...|30.312343889288606|31.605754207613128| 34.17764296984897| 41.29678702929928| 57.61296256284001|60.235508594173886| 72.98160523827542|\n",
      "|2015-06-12T17:30:...|121.08867287840695| 134.9590510955942|141.20552299254044| 85.19826915024544| 84.67957790439822| 80.57414093737533| 68.36694021013216|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Data frame type: <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Import other modules not related to PySpark\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import json\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from datetime import *\n",
    "import statistics as stats\n",
    "# This helps auto print out the items without explixitly using 'print'\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "%matplotlib inline\n",
    "\n",
    "# Import PySpark related modules\n",
    "import pyspark\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import lit, desc, col, size, array_contains\\\n",
    ", isnan, udf, hour, array_min, array_max, countDistinct\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "MAX_MEMORY = '15G'\n",
    "# Initialize a spark session.\n",
    "conf = pyspark.SparkConf().setMaster(\"local[*]\") \\\n",
    "        .set('spark.executor.heartbeatInterval', 10000) \\\n",
    "        .set('spark.network.timeout', 10000) \\\n",
    "        .set(\"spark.core.connection.ack.wait.timeout\", \"3600\") \\\n",
    "        .set(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "        .set(\"spark.driver.memory\", MAX_MEMORY)\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"SOBD2023\") \\\n",
    "        .config(conf=conf) \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = init_spark()\n",
    "filename_data = 'dataindiv/14.csv'\n",
    "# Загружаем датасет,выводим первые 5 строк \n",
    "df = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .csv(\"dataindiv/8.csv\")\n",
    "\n",
    "\n",
    "# Далее для удобства берем только первые 8 столбцов и определяем тип их данных\n",
    "\n",
    "df = df[\"timestamp\", \"actual_consumption\", \"load_00\", \"load_01\", \"load_02\", \"load_03\", \"load_04\", \"load_05\"]\n",
    "df.show()\n",
    "\n",
    "print('Data frame type: ' + str(type(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c606f-8a5b-4814-87ef-3c8e6f3eebbb",
   "metadata": {},
   "source": [
    "2. Обзор датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7dd7ee-8189-4552-9d01-4bd3e2410a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data overview\n",
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- actual_consumption: string (nullable = true)\n",
      " |-- load_00: string (nullable = true)\n",
      " |-- load_01: string (nullable = true)\n",
      " |-- load_02: string (nullable = true)\n",
      " |-- load_03: string (nullable = true)\n",
      " |-- load_04: string (nullable = true)\n",
      " |-- load_05: string (nullable = true)\n",
      "\n",
      "Columns overview\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actual_consumption</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>load_00</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>load_01</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>load_02</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>load_03</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>load_04</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>load_05</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column Name Data type\n",
       "0           timestamp    string\n",
       "1  actual_consumption    string\n",
       "2             load_00    string\n",
       "3             load_01    string\n",
       "4             load_02    string\n",
       "5             load_03    string\n",
       "6             load_04    string\n",
       "7             load_05    string"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Data overview')\n",
    "df.printSchema()\n",
    "print('Columns overview')\n",
    "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a9d78-e970-4ac0-88a2-dda5abe8fff4",
   "metadata": {},
   "source": [
    "Как мы видим, тип данных определился неправильно. Соответственно, необходимо восстановить исходные типы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48701c85-28a0-487f-8b21-512310c6200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "df = df.withColumn(\"actual_consumption\", df.actual_consumption.cast(IntegerType()))\n",
    "df = df.withColumn(\"load_00\", df.load_00.cast(FloatType()))\n",
    "df = df.withColumn(\"load_01\", df.load_01.cast(FloatType()))\n",
    "df = df.withColumn(\"load_02\", df.load_02.cast(FloatType()))\n",
    "df = df.withColumn(\"load_03\", df.load_03.cast(FloatType()))\n",
    "df = df.withColumn(\"load_04\", df.load_04.cast(FloatType()))\n",
    "df = df.withColumn(\"load_05\", df.load_05.cast(FloatType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc5add-6aa3-49b4-abc4-cdb0cd4bde1a",
   "metadata": {},
   "source": [
    "Проверим значения еще раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d200353b-f74d-434e-b5c3-2956ef9d1ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data overview\n",
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- actual_consumption: integer (nullable = true)\n",
      " |-- load_00: float (nullable = true)\n",
      " |-- load_01: float (nullable = true)\n",
      " |-- load_02: float (nullable = true)\n",
      " |-- load_03: float (nullable = true)\n",
      " |-- load_04: float (nullable = true)\n",
      " |-- load_05: float (nullable = true)\n",
      "\n",
      "Columns overview\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actual_consumption</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>load_00</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>load_01</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>load_02</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>load_03</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>load_04</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>load_05</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column Name Data type\n",
       "0           timestamp    string\n",
       "1  actual_consumption       int\n",
       "2             load_00     float\n",
       "3             load_01     float\n",
       "4             load_02     float\n",
       "5             load_03     float\n",
       "6             load_04     float\n",
       "7             load_05     float"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Data overview')\n",
    "df.printSchema()\n",
    "print('Columns overview')\n",
    "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4676e2f-7f82-4753-ab9b-2d43ece8c52d",
   "metadata": {},
   "source": [
    "3. Поиск пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f9effc-5648-4f4f-9f63-53514337024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns overview\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actual_consumption</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>load_00</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>load_01</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>load_02</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>load_03</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>load_04</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>load_05</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column Name Data type\n",
       "0           timestamp    string\n",
       "1  actual_consumption       int\n",
       "2             load_00     float\n",
       "3             load_01     float\n",
       "4             load_02     float\n",
       "5             load_03     float\n",
       "6             load_04     float\n",
       "7             load_05     float"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Columns overview')\n",
    "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265e79e4-163d-4834-94f3-cb415a055fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>actual_consumption</th>\n",
       "      <th>load_00</th>\n",
       "      <th>load_01</th>\n",
       "      <th>load_02</th>\n",
       "      <th>load_03</th>\n",
       "      <th>load_04</th>\n",
       "      <th>load_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  actual_consumption  load_00  load_01  load_02  load_03  load_04  \\\n",
       "0          0                   0        0        0        0        0        0   \n",
       "\n",
       "   load_05  \n",
       "0        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns = ['timestamp', 'actual_consumption', 'load_00',\"load_01\",\"load_02\",\"load_03\", \"load_04\", \"load_05\"]\n",
    "string_columns = [\"timestamp\"]\n",
    "missing_values = {}\n",
    "for index, column in enumerate(df.columns):\n",
    "    if column in string_columns:    # check string columns with None and Null values\n",
    "#         missing_count = df.filter(col(column).eqNullSafe(None) | col(column).isNull()).count()\n",
    "#         missing_values.update({column: missing_count})\n",
    "        missing_count = df.filter(col(column).eqNullSafe(None) | col(column).isNull()).count()\n",
    "        missing_values.update({column:missing_count})\n",
    "    if column in numeric_columns:  # check zeroes, None, NaN\n",
    "        missing_count = df.where(col(column).isin([None,np.nan])).count()\n",
    "        missing_values.update({column:missing_count})\n",
    "missing_df = pd.DataFrame.from_dict([missing_values])\n",
    "missing_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d08f4c-7164-45c3-b0c0-cca144826aaf",
   "metadata": {},
   "source": [
    "4. Поиск выбросов и их устранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ebce803-5794-4ee5-a401-712bd9c6e8ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'when' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m upper_bound \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Создаем новый столбец с замененными выбросами\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mwhen\u001b[49m(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_consumption\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m lower_bound, Q1)\u001b[38;5;241m.\u001b[39mwhen(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_consumption\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m upper_bound, Q3)\u001b[38;5;241m.\u001b[39motherwise(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_consumption\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Удаляем старый столбец и переименовываем новый\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_consumption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_consumption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'when' is not defined"
     ]
    }
   ],
   "source": [
    "# Вычисляем Q1 и Q3 для actual_consumption\n",
    "Q1 = df.approxQuantile(\"actual_consumption\", [0.25], 0)[0]\n",
    "Q3 = df.approxQuantile(\"actual_consumption\", [0.75], 0)[0]\n",
    "\n",
    "# Вычисляем IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Определяем границы выбросов\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Создаем новый столбец с замененными выбросами\n",
    "df = df.withColumn(\"new_value\", when(col(\"actual_consumption\") < lower_bound, Q1).when(col(\"actual_consumption\") > upper_bound, Q3).otherwise(col(\"actual_consumption\")))\n",
    "\n",
    "# Удаляем старый столбец и переименовываем новый\n",
    "df = df.drop(\"actual_consumption\").withColumnRenamed(\"new_value\", \"actual_consumption\")\n",
    "\n",
    "# Теперь повторряем эту операцию для каждого столбца\n",
    "\n",
    "Q1 = df.approxQuantile(\"load_00\", [0.25], 0)[0]\n",
    "Q3 = df.approxQuantile(\"load_00\", [0.75], 0)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df.withColumn(\"new_value\", when(col(\"load_00\") < lower_bound, Q1).when(col(\"load_00\") > upper_bound, Q3).otherwise(col(\"load_00\")))\n",
    "df = df.drop(\"load_00\").withColumnRenamed(\"new_value\", \"load_00\")\n",
    "\n",
    "Q1 = df.approxQuantile(\"load_01\", [0.25], 0)[0]\n",
    "Q3 = df.approxQuantile(\"load_01\", [0.75], 0)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df.withColumn(\"new_value\", when(col(\"load_01\") < lower_bound, Q1).when(col(\"load_01\") > upper_bound, Q3).otherwise(col(\"load_01\")))\n",
    "df = df.drop(\"load_01\").withColumnRenamed(\"new_value\", \"load_01\")\n",
    "\n",
    "Q1 = df.approxQuantile(\"load_02\", [0.25], 0)[0]\n",
    "Q3 = df.approxQuantile(\"load_02\", [0.75], 0)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df.withColumn(\"new_value\", when(col(\"load_02\") < lower_bound, Q1).when(col(\"load_02\") > upper_bound, Q3).otherwise(col(\"load_02\")))\n",
    "df = df.drop(\"load_02\").withColumnRenamed(\"new_value\", \"load_02\")\n",
    "\n",
    "Q1 = df.approxQuantile(\"load_03\", [0.25], 0)[0]\n",
    "Q3 = df.approxQuantile(\"load_03\", [0.75], 0)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df.withColumn(\"new_value\", when(col(\"load_03\") < lower_bound, Q1).when(col(\"load_03\") > upper_bound, Q3).otherwise(col(\"load_03\")))\n",
    "df = df.drop(\"load_03\").withColumnRenamed(\"new_value\", \"load_03\")\n",
    "\n",
    "Q1 = df.approxQuantile(\"load_04\", [0.25], 0)[0]\n",
    "Q3 = df.approxQuantile(\"load_04\", [0.75], 0)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df.withColumn(\"new_value\", when(col(\"load_04\") < lower_bound, Q1).when(col(\"load_04\") > upper_bound, Q3).otherwise(col(\"load_04\")))\n",
    "df = df.drop(\"load_04\").withColumnRenamed(\"new_value\", \"load_04\")\n",
    "\n",
    "Q1 = df.approxQuantile(\"load_05\", [0.25], 0)[0]\n",
    "Q3 = df.approxQuantile(\"load_05\", [0.75], 0)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df.withColumn(\"new_value\", when(col(\"load_05\") < lower_bound, Q1).when(col(\"load_05\") > upper_bound, Q3).otherwise(col(\"load_05\")))\n",
    "df = df.drop(\"load_05\").withColumnRenamed(\"new_value\", \"load_05\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e79e1-7ae2-41ec-b372-2705e82862f3",
   "metadata": {},
   "source": [
    "5. Вычисляем статистические показатели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3a3f7-1227-4e9f-b686-23c05f36b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем статистики для столбцов \"actual_consumption\", \"load_00\", \"load_01\", \"load_02\", \"load_03\", \"load_04\", \"load_05\"\n",
    "stats = df.select(\"actual_consumption\", \"load_00\", \"load_01\", \"load_02\", \"load_03\", \"load_04\", \"load_05\").summary()\n",
    "stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1dfe25-7678-48c5-bfb1-76882c7cc6e4",
   "metadata": {},
   "source": [
    "6. Визуализация распределения наиболее важных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494855f-746a-4140-9542-99529eece788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Выбираем признаки\n",
    "important_cols = [\"actual_consumption\", \"load_00\", \"load_01\", \"load_02\", \"load_03\", \"load_04\", \"load_05\"]\n",
    "\n",
    "# Создаем новый датафрейм с выбранными признаками\n",
    "df_selected = df.select(important_cols)\n",
    "\n",
    "# Преобразуем датафрейм PySpark в датафрейм Pandas\n",
    "df_pd = df_selected.toPandas()\n",
    "\n",
    "# Строим гистограммы для каждого признака\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(important_cols), figsize=(10, 5))\n",
    "for i, col in enumerate(important_cols):\n",
    "    ax = axes[i]\n",
    "    ax.hist(df_pd[col], bins=20)\n",
    "    ax.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cacade-0783-4952-b714-24f8a3154e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "# Просматриваем первые пять строк датасета\n",
    "df.show(5)\n",
    "\n",
    "# Вычисляем корреляцию Пирсона между колонками \"load_00\" и \"load_01\"\n",
    "pearson_corr = df.corr(\"actual_consumption\", \"load_01\", method=\"pearson\")\n",
    "print(f\"Корреляция Пирсона между actual_consumption и load_01: {pearson_corr}\")\n",
    "\n",
    "# Вычисляем корреляцию Пирсона между колонками \"load_02\" и \"load_03\"\n",
    "pearson_corr = df.corr(\"actual_consumption\", \"load_03\", method=\"pearson\")\n",
    "print(f\"Корреляция Пирсона между actual_consumption и load_01: {pearson_corr}\")\n",
    "\n",
    "# Вычисляем корреляцию Пирсона между колонками \"load_04\" и \"load_05\"\n",
    "pearson_corr = df.corr(\"actual_consumption\", \"load_05\", method=\"pearson\")\n",
    "print(f\"Корреляция Пирсона между actual_consumption и load_01: {pearson_corr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec885e42-84e8-4da7-9c60-e56de89fad9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
